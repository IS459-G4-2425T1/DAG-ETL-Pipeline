{
	"metadata": {
		"kernelspec": {
			"name": "glue_pyspark",
			"display_name": "Glue PySpark",
			"language": "python"
		},
		"language_info": {
			"name": "Python_Glue_Session",
			"mimetype": "text/x-python",
			"codemirror_mode": {
				"name": "python",
				"version": 3
			},
			"pygments_lexer": "python3",
			"file_extension": ".py"
		}
	},
	"nbformat_minor": 4,
	"nbformat": 4,
	"cells": [
		{
			"cell_type": "markdown",
			"source": "# AWS Glue Studio Notebook\n##### You are now running a AWS Glue Studio notebook; To start using your notebook you need to start an AWS Glue Interactive Session.\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "markdown",
			"source": "#### Optional: Run this cell to see available notebook commands (\"magics\").\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "%help",
			"metadata": {
				"trusted": true,
				"editable": true
			},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "markdown",
			"source": "####  Run this cell to set up and start your interactive session.\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "%idle_timeout 2880\n%glue_version 4.0\n%worker_type G.1X\n%number_of_workers 5\n\nimport sys\nfrom awsglue.transforms import *\nfrom awsglue.utils import getResolvedOptions\nfrom pyspark.context import SparkContext\nfrom awsglue.context import GlueContext\nfrom awsglue.job import Job\n  \nsc = SparkContext.getOrCreate()\nglueContext = GlueContext(sc)\nspark = glueContext.spark_session\njob = Job(glueContext)",
			"metadata": {
				"trusted": true,
				"editable": true
			},
			"execution_count": 1,
			"outputs": [
				{
					"name": "stdout",
					"text": "Welcome to the Glue Interactive Sessions Kernel\nFor more information on available magic commands, please type %help in any new cell.\n\nPlease view our Getting Started page to access the most up-to-date information on the Interactive Sessions kernel: https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions.html\nInstalled kernel version: 1.0.5 \nCurrent idle_timeout is None minutes.\nidle_timeout has been set to 2880 minutes.\nSetting Glue version to: 4.0\nPrevious worker type: None\nSetting new worker type to: G.1X\nPrevious number of workers: None\nSetting new number of workers to: 5\nTrying to create a Glue session for the kernel.\nSession Type: glueetl\nWorker Type: G.1X\nNumber of Workers: 5\nIdle Timeout: 2880\nSession ID: fe962335-b012-40d6-ba2b-0dca0ffd7157\nApplying the following default arguments:\n--glue_kernel_version 1.0.5\n--enable-glue-datacatalog true\nWaiting for session fe962335-b012-40d6-ba2b-0dca0ffd7157 to get into ready status...\nSession fe962335-b012-40d6-ba2b-0dca0ffd7157 has been created.\n\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "from awsglue.dynamicframe import DynamicFrame\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.window import Window\nfrom pyspark.sql.functions import col, avg, when, floor, trim, concat, lit, desc, lag, sum, to_date, concat_ws, date_format\nfrom pyspark.sql import functions as F",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 15,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "s3_path = \"s3://live-flight-schedule-data/live_flight_schedule_data.json\"\n\ntry:\n    # Step 1: Load the JSON file using Spark with multiLine option\n    # This handles JSON files that are not line-delimited (i.e., single JSON array or object)\n    dataframe = spark.read.option(\"multiLine\", \"true\").json(s3_path)\n    \n    # Check if DataFrame has data\n    if dataframe.rdd.isEmpty():\n        print(\"DataFrame is empty. Please verify the JSON structure and S3 path.\")\n    else:\n        # Step 2: Convert Spark DataFrame to Glue DynamicFrame\n        dynamic_frame = DynamicFrame.fromDF(dataframe, glueContext, \"dynamic_frame\")\n        \n        # Step 3: Flatten the nested fields using 'apply_mapping'\n        flattened_dynamic_frame = dynamic_frame.apply_mapping([\n            # Flattening 'airline' nested structure\n            ('airline.iataCode', 'string', 'airline_iataCode', 'string'),\n            ('airline.icaoCode', 'string', 'airline_icaoCode', 'string'),\n            ('airline.name', 'string', 'airline_name', 'string'),\n\n            # Flattening 'arrival' nested structure\n            ('arrival.actualRunway', 'string', 'arrival_actualRunway', 'string'),\n            ('arrival.actualTime', 'string', 'arrival_actualTime', 'string'),\n            ('arrival.baggage', 'string', 'arrival_baggage', 'string'),\n            ('arrival.delay', 'string', 'arrival_delay', 'string'),\n            ('arrival.estimatedRunway', 'string', 'arrival_estimatedRunway', 'string'),\n            ('arrival.estimatedTime', 'string', 'arrival_estimatedTime', 'string'),\n            ('arrival.gate', 'string', 'arrival_gate', 'string'),\n            ('arrival.iataCode', 'string', 'arrival_iataCode', 'string'),\n            ('arrival.icaoCode', 'string', 'arrival_icaoCode', 'string'),\n            ('arrival.scheduledTime', 'string', 'arrival_scheduledTime', 'string'),\n            ('arrival.terminal', 'string', 'arrival_terminal', 'string'),\n\n            # Flattening 'departure' nested structure\n            ('departure.actualRunway', 'string', 'departure_actualRunway', 'string'),\n            ('departure.actualTime', 'string', 'departure_actualTime', 'string'),\n            ('departure.baggage', 'string', 'departure_baggage', 'string'),\n            ('departure.delay', 'string', 'departure_delay', 'string'),\n            ('departure.estimatedRunway', 'string', 'departure_estimatedRunway', 'string'),\n            ('departure.estimatedTime', 'string', 'departure_estimatedTime', 'string'),\n            ('departure.gate', 'string', 'departure_gate', 'string'),\n            ('departure.iataCode', 'string', 'departure_iataCode', 'string'),\n            ('departure.icaoCode', 'string', 'departure_icaoCode', 'string'),\n            ('departure.scheduledTime', 'string', 'departure_scheduledTime', 'string'),\n            ('departure.terminal', 'string', 'departure_terminal', 'string'),\n\n            # Flattening 'flight' nested structure\n            ('flight.iataNumber', 'string', 'flight_iataNumber', 'string'),\n            ('flight.icaoNumber', 'string', 'flight_icaoNumber', 'string'),\n            ('flight.number', 'string', 'flight_number', 'string'),\n\n            # Top-level fields\n            ('status', 'string', 'status', 'string'),\n            ('type', 'string', 'type', 'string'),\n        ])\n        \n        # Step 4: Convert the flattened DynamicFrame back to DataFrame\n        flattened_df = flattened_dynamic_frame.toDF()\n        \n        # Step 5: Show the DataFrame content to ensure data is loaded correctly\n        print(\"First 5 records in the DataFrame:\")\n        flattened_df.show(5)\n        \nexcept Exception as e:\n    print(f\"Error loading data: {str(e)}\")",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 16,
			"outputs": [
				{
					"name": "stdout",
					"text": "First 5 records in the DataFrame:\n+----------------+----------------+--------------+--------------------+------------------+---------------+-------------+-----------------------+---------------------+------------+----------------+----------------+---------------------+----------------+----------------------+--------------------+-----------------+---------------+-------------------------+-----------------------+--------------+------------------+------------------+-----------------------+------------------+-----------------+-----------------+-------------+------+---------+\n|airline_iataCode|airline_icaoCode|  airline_name|arrival_actualRunway|arrival_actualTime|arrival_baggage|arrival_delay|arrival_estimatedRunway|arrival_estimatedTime|arrival_gate|arrival_iataCode|arrival_icaoCode|arrival_scheduledTime|arrival_terminal|departure_actualRunway|departure_actualTime|departure_baggage|departure_delay|departure_estimatedRunway|departure_estimatedTime|departure_gate|departure_iataCode|departure_icaoCode|departure_scheduledTime|departure_terminal|flight_iataNumber|flight_icaoNumber|flight_number|status|     type|\n+----------------+----------------+--------------+--------------------+------------------+---------------+-------------+-----------------------+---------------------+------------+----------------+----------------+---------------------+----------------+----------------------+--------------------+-----------------+---------------+-------------------------+-----------------------+--------------+------------------+------------------+-----------------------+------------------+-----------------+-----------------+-------------+------+---------+\n|              8E|             BRG|    Bering Air|                null|              null|           null|         null|                   null|                 null|        null|             OBU|            PAOB| 2024-11-03T16:41:...|            null|                  null|                null|             null|             10|                     null|   2024-11-03T16:30:...|          null|               SHG|              PAGH|   2024-11-03T16:20:...|              null|            8E622|           BRG622|          622|active|departure|\n|              GV|             GUN|Grant Aviation|                null|              null|           null|         null|                   null|                 null|        null|             KOT|            PFKO| 2024-11-03T16:40:...|            null|                  null|                null|             null|           null|                     null|                   null|          null|               EMK|              PAEM|   2024-11-03T16:15:...|              null|           GV1230|          GUN1230|         1230|active|departure|\n|              GV|             GUN|Grant Aviation|                null|              null|           null|         null|                   null|                 null|        null|             AUK|            PAUK| 2024-11-03T16:20:...|            null|                  null|                null|             null|           null|                     null|                   null|          null|               EMK|              PAEM|   2024-11-03T16:15:...|              null|           GV1050|          GUN1050|         1050|active|departure|\n|              GV|             GUN|Grant Aviation|                null|              null|           null|         null|                   null|                 null|        null|             SXP|                | 2024-11-03T16:20:...|            null|                  null|                null|             null|           null|                     null|                   null|          null|               EMK|              PAEM|   2024-11-03T16:15:...|              null|           GV1650|          GUN1650|         1650|active|departure|\n|                |                | Private owner|                null|              null|           null|         null|                   null|                 null|        null|             BET|            PABE| 2024-11-03T16:20:...|            null|  2024-11-03T16:32:...|2024-11-03T16:32:...|             null|             17|     2024-11-03T16:32:...|                   null|          null|               EMK|              PAEM|   2024-11-03T16:15:...|              null|                 |                 |         1650|active|departure|\n+----------------+----------------+--------------+--------------------+------------------+---------------+-------------+-----------------------+---------------------+------------+----------------+----------------+---------------------+----------------+----------------------+--------------------+-----------------+---------------+-------------------------+-----------------------+--------------+------------------+------------------+-----------------------+------------------+-----------------+-----------------+-------------+------+---------+\nonly showing top 5 rows\n\n/opt/amazon/spark/python/lib/pyspark.zip/pyspark/sql/dataframe.py:127: UserWarning: DataFrame constructor is internal. Do not directly use it.\n  warnings.warn(\"DataFrame constructor is internal. Do not directly use it.\")\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "***Drop rows with arrival time***",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "# Count the number of rows before dropping rows\ninitial_count = flattened_df.count()\nprint(f\"Number of rows before dropping: {initial_count}\")\n\n# Filter to keep only rows where \"arrival_actualTime\" is null\nfiltered_df = flattened_df.filter(flattened_df[\"arrival_actualTime\"].isNull())\n\n# Count the number of rows after dropping\nfinal_count = filtered_df.count()\nprint(f\"Number of rows after dropping: {final_count}\")",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 17,
			"outputs": [
				{
					"name": "stdout",
					"text": "Number of rows before dropping: 5000\nNumber of rows after dropping: 3368\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "***ONLY GET DOMESTIC FLIGHTS***",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "domestic = ['MLU', 'ILE', 'HSV', 'OMA', 'YAK', 'PBI', 'SDF', 'PNS', 'CMH', 'DCA', 'EAU', 'LBB', 'MSN', 'BHM', 'VIS', 'MKG', 'CLL', 'RNO', 'BFL', 'MAZ', 'LNY', 'LGB', 'MKK', 'MHT', 'CLT', 'ELP', 'DRO', 'RKS', 'SGF', 'COD', 'WYS', 'SLC', 'OAK', 'ATW', 'BGR', 'AMA', 'LFT', 'PDX', 'DAL', 'MEM', 'EUG', 'SAN', 'BPT', 'FLL', 'OAJ', 'CHO', 'MRY', 'SCE', 'OTH', 'ORH', 'ANC', 'PHX', 'CHS', 'RIC', 'CRP', 'AEX', 'FNT', 'BOI', 'OKC', 'BMI', 'GSO', 'MOD', 'EGE', 'KOA', 'CPR', 'ALB', 'SAT', 'PSE', 'LIH', 'TUS', 'SNA', 'SPI', 'PIR', 'KTN', 'AKN', 'ISP', 'MQT', 'JNU', 'TWF', 'BDL', 'RST', 'ELM', 'FAI', 'PSG', 'GSP', 'CHA', 'RAP', 'SBP', 'OGG', 'SIT', 'PSP', 'LWS', 'MCI', 'BIL', 'CDV', 'ITH', 'MFE', 'MIA', 'SRQ', 'SMX', 'MDW', 'PSC', 'GRB', 'PMD', 'TPA', 'GST', 'FAT', 'BET', 'ACT', 'CKB', 'GFK', 'FSM', 'EVV', 'HPN', 'ONT', 'PIH', 'DAY', 'FCA', 'PHF', 'RHI', 'LMT', 'BGM', 'TUL', 'IYK', 'DLG', 'AVL', 'PWM', 'XNA', 'IPL', 'MAF', 'MOB', 'WRG', 'GCC', 'CAE', 'CWA', 'HNL', 'SAV', 'SBA', 'STL', 'KSM', 'VCT', 'BWI', 'BUR', 'CMX', 'MLI', 'FAY', 'GUC', 'SJU', 'LAN', 'SGU', 'EKO', 'ABI', 'MCN', 'ADK', 'ACK', 'MLB', 'LEX', 'IND', 'EWR', 'PVD', 'MFR', 'HLN', 'TXK', 'HTS', 'CIC', 'AUS', 'STT', 'DAB', 'FSD', 'ICT', 'TTN', 'PIT', 'MSP', 'LIT', 'ATL', 'DBQ', 'RDU', 'AGS', 'OME', 'SJT', 'ILM', 'ITO', 'SWF', 'ALO', 'OGD', 'RDD', 'TYR', 'ADQ', 'PUB', 'IAH', 'TVC', 'MBS', 'BTV', 'ABY', 'LAX', 'CLE', 'TLH', 'YUM', 'PLN', 'HVN', 'MSY', 'PFN', 'BUF', 'SEA', 'MGM', 'BLI', 'OTZ', 'TEX', 'ACV', 'CAK', 'MKE', 'BQN', 'JAC', 'CSG', 'TYS', 'IAD', 'JAX', 'DFW', 'MYR', 'SUX', 'CRW', 'ACY', 'GRR', 'SUN', 'SMF', 'AZO', 'MDT', 'CYS', 'STX', 'CID', 'SBN', 'ERI', 'TRI', 'EYW', 'ABE', 'SHV', 'BNA', 'BZN', 'SFO', 'BOS', 'HOU', 'GRK', 'FWA', 'CDC', 'JFK', 'TOL', 'LRD', 'GJT', 'ROW', 'SLE', 'OXR', 'SPS', 'MTJ', 'AVP', 'PHL', 'SPN', 'DSM', 'DTW', 'BIS', 'BJI', 'LAW', 'ORD', 'BTM', 'LNK', 'MCO', 'INL', 'SYR', 'FAR', 'DLH', 'GEG', 'GPT', 'LAS', 'RSW', 'HRL', 'GUM', 'RDM', 'CVG', 'ROA', 'GTF', 'ABQ', 'CMI', 'ASE', 'ROC', 'GGG', 'VPS', 'CEC', 'RFD', 'DEN', 'COS', 'DUT', 'GNV', 'SCC', 'IDA', 'CLD', 'ORF', 'PIA', 'YKM', 'HDN', 'JAN', 'ANI', 'SJC', 'BRW', 'FLG', 'LGA', 'BTR', 'MSO', 'APF', 'LSE']",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 18,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "new_df = filtered_df.filter(\n    filtered_df[\"arrival_iataCode\"].isin(domestic) & filtered_df[\"departure_iataCode\"].isin(domestic)\n)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 19,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "***NEXT***",
			"metadata": {
				"tags": []
			}
		},
		{
			"cell_type": "code",
			"source": "# Step 5: Select the specific columns you want to keep\ncolumns_to_select = [\n    'departure_scheduledTime',\n    'departure_iataCode',\n    'arrival_iataCode',\n    'airline_iataCode',\n    'flight_iataNumber',\n    'arrival_scheduledTime'\n]\n\n# Create a new DataFrame 'df' by selecting specific columns\ndf = new_df.select(*columns_to_select)\n\n# Show the first few records of the new DataFrame\nprint(\"First 5 records in the new DataFrame:\")\ndf.show(5)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 20,
			"outputs": [
				{
					"name": "stdout",
					"text": "First 5 records in the new DataFrame:\n+-----------------------+------------------+----------------+----------------+-----------------+---------------------+\n|departure_scheduledTime|departure_iataCode|arrival_iataCode|airline_iataCode|flight_iataNumber|arrival_scheduledTime|\n+-----------------------+------------------+----------------+----------------+-----------------+---------------------+\n|   2024-11-03T18:51:...|               DFW|             SPS|              AS|           AS6185| 2024-11-03T19:53:...|\n|   2024-11-03T18:51:...|               DFW|             SPS|              QR|           QR2355| 2024-11-03T19:53:...|\n|   2024-11-03T18:51:...|               DFW|             SPS|              QR|           QR2328| 2024-11-03T19:53:...|\n|   2024-11-03T18:51:...|               DFW|             SPS|              AA|           AA4921| 2024-11-03T19:53:...|\n|   2024-11-03T18:15:...|               PUB|             CLD|                |                 | 2024-11-03T19:28:...|\n+-----------------------+------------------+----------------+----------------+-----------------+---------------------+\nonly showing top 5 rows\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "from pyspark.sql.functions import split, regexp_replace, year, month, dayofmonth\n\n# Step 1: Split 'departure_scheduledTime' into 'flightdate' and 'departure_time'\ndf = df.withColumn(\"flightdate\", split(col(\"departure_scheduledTime\"), \"T\")[0])\ndf = df.withColumn(\"departure_time\", split(col(\"departure_scheduledTime\"), \"T\")[1])\n\n# Step 2: Create 'deptime' column by converting 'departure_time' to an integer format \"HHMM\"\n# Extract \"HHMM\" portion by replacing \":\" and truncating milliseconds\ndf = df.withColumn(\"deptime\", regexp_replace(col(\"departure_time\"), \":\", \"\").substr(0, 4).cast(\"int\"))\ndf = df.withColumn(\"year\", year(col(\"flightdate\").cast(\"date\")))\ndf = df.withColumn(\"month\", month(col(\"flightdate\").cast(\"date\")))\ndf = df.withColumn(\"dateofmonth\", dayofmonth(col(\"flightdate\").cast(\"date\")))\n\n# Step 3: Drop the original 'departure_scheduledTime' column if itâ€™s no longer needed\ndf = df.drop(\"departure_scheduledTime\", \"departure_time\")\n\ndf = df.withColumnRenamed('departure_iataCode', 'origin') \\\n        .withColumnRenamed('arrival_iataCode', 'dest') \\\n        .withColumnRenamed('airline_iataCode', 'uniquecarrier') \\\n        .withColumnRenamed('flight_iataNumber', 'flightnum') \\\n        .withColumnRenamed('arrival_scheduledTime', 'crsarrival') \n\n# Step 2: Show the updated DataFrame with the new columns\ndf.show(5)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 21,
			"outputs": [
				{
					"name": "stdout",
					"text": "+------+----+-------------+---------+--------------------+----------+-------+----+-----+-----------+\n|origin|dest|uniquecarrier|flightnum|          crsarrival|flightdate|deptime|year|month|dateofmonth|\n+------+----+-------------+---------+--------------------+----------+-------+----+-----+-----------+\n|   DFW| SPS|           AS|   AS6185|2024-11-03T19:53:...|2024-11-03|   1851|2024|   11|          3|\n|   DFW| SPS|           QR|   QR2355|2024-11-03T19:53:...|2024-11-03|   1851|2024|   11|          3|\n|   DFW| SPS|           QR|   QR2328|2024-11-03T19:53:...|2024-11-03|   1851|2024|   11|          3|\n|   DFW| SPS|           AA|   AA4921|2024-11-03T19:53:...|2024-11-03|   1851|2024|   11|          3|\n|   PUB| CLD|             |         |2024-11-03T19:28:...|2024-11-03|   1815|2024|   11|          3|\n+------+----+-------------+---------+--------------------+----------+-------+----+-----+-----------+\nonly showing top 5 rows\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "***STORING***",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "# s3 = \"s3://live-flight-schedule-data/clean-live-data.json\"\n\n# df.write \\\n#     .mode(\"overwrite\") \\\n#     .json(s3)\nimport json\nimport boto3\n\n# AWS S3 Configuration\ns3_client = boto3.client('s3')\nbucket_name = 'live-flight-schedule-data'\njson_filename = 'clean-live-data/new.json'\n\n# Collect data as a list of dictionaries\ndata = df.toPandas().to_dict(orient='records')\n\n# Convert list of dictionaries to a JSON array string\njson_array = json.dumps(data)\n\n# Upload the JSON array directly to S3\ntry:\n    s3_client.put_object(Bucket=bucket_name, Key=json_filename, Body=json_array)\n    print(f'Successfully written JSON array to s3://{bucket_name}/{output_key}')\nexcept Exception as e:\n    print(f\"Error uploading JSON to S3: {e}\")",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 22,
			"outputs": [
				{
					"name": "stdout",
					"text": "{'ResponseMetadata': {'RequestId': 'KQYX4JQEHBPKHA0R', 'HostId': '3mTBXGSPtbcxbU5XPLlpdzwQuZGpYKnqBXGGURk4aZVwnOmUzZXx6b4OvrS946TN+zcdcVcTuvk=', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amz-id-2': '3mTBXGSPtbcxbU5XPLlpdzwQuZGpYKnqBXGGURk4aZVwnOmUzZXx6b4OvrS946TN+zcdcVcTuvk=', 'x-amz-request-id': 'KQYX4JQEHBPKHA0R', 'date': 'Sun, 10 Nov 2024 08:52:00 GMT', 'x-amz-server-side-encryption': 'AES256', 'etag': '\"459989d6eff4010f8a04a3b7641e22c8\"', 'content-length': '0', 'server': 'AmazonS3'}, 'RetryAttempts': 0}, 'ETag': '\"459989d6eff4010f8a04a3b7641e22c8\"', 'ServerSideEncryption': 'AES256'}\nError uploading JSON to S3: name 'output_key' is not defined\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "print(type(df)) ",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 10,
			"outputs": [
				{
					"name": "stdout",
					"text": "<class 'pyspark.sql.dataframe.DataFrame'>\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "",
			"metadata": {},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "code",
			"source": "",
			"metadata": {},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "code",
			"source": "",
			"metadata": {},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "code",
			"source": "",
			"metadata": {},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "code",
			"source": "",
			"metadata": {},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "code",
			"source": "",
			"metadata": {},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "markdown",
			"source": "#### Example: Create a DynamicFrame from a table in the AWS Glue Data Catalog and display its schema\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "# dyf = glueContext.create_dynamic_frame.from_catalog(database='database_name', table_name='table_name')\n# dyf.printSchema()",
			"metadata": {
				"trusted": true,
				"editable": true
			},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "markdown",
			"source": "#### Example: Convert the DynamicFrame to a Spark DataFrame and display a sample of the data\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "# df = dyf.toDF()\n# df.show()",
			"metadata": {
				"trusted": true,
				"editable": true
			},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "markdown",
			"source": "#### Example: Visualize data with matplotlib\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "# import matplotlib.pyplot as plt\n\n# # Set X-axis and Y-axis values\n# x = [5, 2, 8, 4, 9]\n# y = [10, 4, 8, 5, 2]\n  \n# # Create a bar chart \n# plt.bar(x, y)\n  \n# # Show the plot\n# %matplot plt",
			"metadata": {
				"trusted": true,
				"editable": true
			},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "markdown",
			"source": "#### Example: Write the data in the DynamicFrame to a location in Amazon S3 and a table for it in the AWS Glue Data Catalog\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "# s3output = glueContext.getSink(\n#   path=\"s3://bucket_name/folder_name\",\n#   connection_type=\"s3\",\n#   updateBehavior=\"UPDATE_IN_DATABASE\",\n#   partitionKeys=[],\n#   compression=\"snappy\",\n#   enableUpdateCatalog=True,\n#   transformation_ctx=\"s3output\",\n# )\n# s3output.setCatalogInfo(\n#   catalogDatabase=\"demo\", catalogTableName=\"populations\"\n# )\n# s3output.setFormat(\"glueparquet\")\n# s3output.writeFrame(DyF)",
			"metadata": {
				"trusted": true,
				"editable": true
			},
			"execution_count": null,
			"outputs": []
		}
	]
}